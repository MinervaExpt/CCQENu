{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import ROOT\n",
    "import commentjson\n",
    "import PlotUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if (\"root\" in sys.argv[1]): \n",
    "    configloc = \"root\"\n",
    "    print(\"getting config from root input \" , sys.argv[1] )\n",
    "    inputname = sys.argv[1]\n",
    "    f = TFile::Open(inputname, \"READONLY\")\n",
    "   \n",
    "\n",
    "    allconfigs[\"main\"] = (f.Get(\"main\").GetTitle())\n",
    "    allconfigs[\"varsFile\"] = (f.Get(\"varsFile\").GetTitle())\n",
    "    allconfigs[\"cutsFile\"] = (f.Get(\"cutsFile\").GetTitle())\n",
    "    allconfigs[\"samplesFile\"] = (f.Get(\"samplesFile\").GetTitle())\n",
    "    \n",
    "\n",
    "    singlesample = 0;\n",
    "    # see if the root file has already had fits done - these will be used in the cross section fit.\n",
    "    hasbkgsub = f.Get(\"fitconfig\") != 0;\n",
    "\n",
    "    if len(sys.argv)  > 1 :\n",
    "        usetune = argv[2]\n",
    "    \n",
    "    else:\n",
    "    # this is the old way\n",
    "        print(\"getting config from command line \" , sys.argv[1] )\n",
    "        configloc = \"disk\"\n",
    "        int prescale = 100\n",
    "        if (argc > 2):\n",
    "            inputtag += \"_\" + (sys.argv[2]);\n",
    "        \n",
    "    std::string asample;\n",
    "\n",
    "    if (argc > 3) {\n",
    "        asample = (argv[3]);\n",
    "        singlesample = 1;\n",
    "    } else {\n",
    "        singlesample = 0;\n",
    "    }\n",
    "    NuConfig* theconfig;\n",
    "    theconfig.Read((argv[1]) + \".json\");\n",
    "    allconfigs[\"main\"] = theconfig;\n",
    "    inputname = theconfig.GetString(\"outRoot\") + \"_\" + inputtag + \".root\";\n",
    "    f = TFile::Open(inputname.c_str(), \"READONLY\");\n",
    "    # f.ls();\n",
    "}\n",
    "\n",
    "    # allconfigs[\"main\"].Print();\n",
    "\n",
    "    # code used to use config now use allconfigs[\"main\"]\n",
    "    std::vector<std::string> AnalyzeVariables = allconfigs[\"main\"].GetStringVector(\"AnalyzeVariables\");\n",
    "    std::vector<std::string> AnalyzeVariables2D = allconfigs[\"main\"].GetStringVector(\"Analyze2DVariables\");\n",
    "    std::vector<std::string> SampleRequest;\n",
    "\n",
    "    # either get sample from command line or from the list in the config\n",
    "    if (!singlesample) {\n",
    "        SampleRequest = allconfigs[\"main\"].GetStringVector(\"runsamples\");\n",
    "    } else {\n",
    "        SampleRequest.push_back(asample);\n",
    "    }\n",
    "    std::string playlist = allconfigs[\"main\"].GetString(\"playlist\");\n",
    "\n",
    "    int m_fluxUniverses = allconfigs[\"main\"].GetInt(\"fluxUniverses\");\n",
    "\n",
    "    #========================================= Now do some analysis\n",
    "\n",
    "    MnvH1D* h_flux_dewidthed = GetFlux(allconfigs);\n",
    "\n",
    "    double flux = h_flux_dewidthed.Integral();\n",
    "    # make containers for different analysis levels\n",
    "    std::map<std::string, MnvH1D*> h_flux_ebins;\n",
    "\n",
    "    # now loop over histograms, unsmear, efficiency correct and normalize\n",
    "\n",
    "    # unfolding setup\n",
    "    MinervaUnfold::MnvUnfold unfold;\n",
    "    # MnvH2D* MigrationMatrix;\n",
    "    double num_iter = 5;\n",
    "\n",
    "    # input 4 D hist-map\n",
    "\n",
    "    # arguments will be sample, variable, type, category\n",
    "    # order in histogram name is sample___category___variable___type\n",
    "    # type is reconstructed, truth...\n",
    "    # category is qelike, qelikenot ...\n",
    "\n",
    "    std::map<std::string, std::map<std::string, std::map<std::string, std::map<std::string, MnvH1D*> > > > hists1D;\n",
    "\n",
    "    std::map<std::string, std::map<std::string, std::map<std::string, std::map<std::string, MnvH2D*> > > > hists2D;\n",
    "\n",
    "    std::map<std::string, std::map<std::string, std::map<std::string, std::map<std::string, MnvH2D*> > > > response1D;\n",
    "\n",
    "    std::map<std::string, std::map<std::string, std::map<std::string, std::map<std::string, MnvH2D*> > > > response2D;\n",
    "\n",
    "    # f.ls();\n",
    "\n",
    "    std::vector<std::string> keys;\n",
    "\n",
    "    MnvH1D* null = new MnvH1D(\"null\", \"empty histogram\", 1, 0., 1.);\n",
    "    MnvH2D* null2 = new MnvH2D(\"null2\", \"empty histogram\", 1, 0., 1., 1, 0., 1.);\n",
    "\n",
    "    std::vector<std::string> samples;\n",
    "    std::vector<std::string> variables;\n",
    "    std::vector<std::string> categories;\n",
    "    std::vector<std::string> types;\n",
    "\n",
    "    # this is the old read in the POT.  They are also in a vector which Amit like having\n",
    "    TH1D* h_pot = (TH1D*)f.Get(\"POT_summary\");\n",
    "    h_pot.Print(\"ALL\");\n",
    "\n",
    "    double dataPOT = h_pot.GetBinContent(1);\n",
    "    double mcPOTprescaled = h_pot.GetBinContent(3);\n",
    "    double POTScale = dataPOT / mcPOTprescaled;\n",
    "    delete h_pot;\n",
    "    double norm = 1. / dataPOT / targets;\n",
    "    TNamed targetobj(\"targets\", Form(\"%6e\", targets));\n",
    "\n",
    "    print(\" integrated luminosity is \" , 1 / norm / 1.E24 , \"barns^-1\" )\n",
    "\n",
    "    print(\" POT MC \" , mcPOTprescaled )\n",
    "    print(\" POT DATA \" , dataPOT )\n",
    "\n",
    "    for (auto k : *f.GetListOfKeys()) {\n",
    "        keys.push_back(k.GetName());\n",
    "        std::string key = k.GetName\n",
    "        std::string hNd = parsekey[0];\n",
    "        std::string sample = parsekey[1];\n",
    "        std::string category = parsekey[2];\n",
    "        std::string variable = parsekey[3];\n",
    "        std::string type = parsekey[4];\n",
    "        \n",
    "        if (type.find(\"type\")!= string::npos) {\n",
    "            print(\" found a type\" , type )\n",
    "            continue;\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "\n",
    "        # build lists of all valid tags\n",
    "        # only count sample that you requested\n",
    "        if (!checktag(SampleRequest, sample)) {\n",
    "            print(\" skip a sample:\" , sample )\n",
    "            continue;\n",
    "        }\n",
    "        # build lists of tags\n",
    "        if (!checktag(samples, sample)) {\n",
    "            samples.push_back(sample);\n",
    "            print(\" add a sample: \" , sample )\n",
    "        }\n",
    "\n",
    "        if (!checktag(categories, category)) {\n",
    "            categories.push_back(category);\n",
    "            print(\" add a category: \" , category )\n",
    "        }\n",
    "        if (!checktag(variables, variable)) {\n",
    "            variables.push_back(variable);\n",
    "            print(\" add a variable: \" , variable )\n",
    "        }\n",
    "        if (!checktag(types, type)) {\n",
    "            types.push_back(type);\n",
    "            print(\" add a type: \" , type )\n",
    "        }\n",
    "        # get the histogram\n",
    "        TNamed* me = f.GetKey(key.c_str());\n",
    "        print(\" Done with parsing\" )\n",
    "\n",
    "        # 1D hists\n",
    "        if (key.find(\"h2D\") == std::string::npos) {\n",
    "            # if response in name its a 2D so do a cast to MnvH2D\n",
    "            if (key.find(\"migration\") != std::string::npos) {\n",
    "                MnvH2D* hist = (MnvH2D*)(f.Get(key.c_str()));\n",
    "                if (hist != 0) {\n",
    "                    response1D[sample][variable][type][category] = hist.Clone();\n",
    "                    # response1D[sample][variable][type][category].Print();\n",
    "                    response1D[sample][variable][type][category].SetDirectory(0);\n",
    "                    print(\" migration \" , sample , \" \" , variable , \" \" , type , \" \" , category )\n",
    "                    delete hist;\n",
    "                } else {\n",
    "                    print(\"could not read \" , key )\n",
    "                    response1D[sample][variable][type][category] = 0;\n",
    "                }\n",
    "            }\n",
    "            # it's normal so it's a 1D.\n",
    "            else {\n",
    "                MnvH1D* temp = (MnvH1D*)(f.Get(key.c_str()));\n",
    "                if (temp != 0) {\n",
    "                    hists1D[sample][variable][type][category] = temp.Clone();\n",
    "                    hists1D[sample][variable][type][category].Print();\n",
    "                    hists1D[sample][variable][type][category].SetDirectory(0);\n",
    "                    print(\" hist 1D \" , sample , \" \" , variable , \" \" , type , \" \" , category , \" \" , hists1D[sample][variable][type][category].GetName() )\n",
    "                    delete temp;\n",
    "                } else {\n",
    "                    print(\"could not read \" , key )\n",
    "                    hists1D[sample][variable][type][category] = 0;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # 2D hists\n",
    "        else if (hNd == \"h2D\" || key.find(\"h2D\") != std::string::npos) {\n",
    "            std::vector<std::string> partsof2D = split(variable, \"_\");\n",
    "            MnvH2D* hist = (MnvH2D*)(f.Get(key.c_str()));\n",
    "            # Check if response is in its name\n",
    "            if (hist != 0) {\n",
    "                if (key.find(\"migration\") != std::string::npos) {\n",
    "                    response2D[sample][variable][type][category] = hist.Clone();\n",
    "                    response2D[sample][variable][type][category].Print();\n",
    "                    response2D[sample][variable][type][category].SetDirectory(0);\n",
    "                    print(\" 2D migration \" , sample , \" \" , variable , \" \" , type , \" \" , category )\n",
    "                    delete hist;\n",
    "                } else {\n",
    "                    hists2D[sample][variable][type][category] = hist.Clone();\n",
    "                    hists2D[sample][variable][type][category].Print();\n",
    "                    hists2D[sample][variable][type][category].SetDirectory(0);\n",
    "                    print(\" hist 2D \" , sample , \" \" , variable , \" \" , type , \" \" , category )\n",
    "                    delete hist;\n",
    "                }\n",
    "            } else {\n",
    "                print(\"could not read \" , key )\n",
    "                if (key.find(\"migration\") != std::string::npos) {\n",
    "                    response2D[sample][variable][type][category] = 0;\n",
    "                } else {\n",
    "                    hists2D[sample][variable][type][category] = 0;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # define the output file\n",
    "    std::string pdfname;\n",
    "    std::string outroot;\n",
    "    std::string stune = \"_untuned\";\n",
    "    if (usetune) stune = \"_tuned\";\n",
    "    if (singlesample) {\n",
    "        std::string outname = inputname.replace(inputname.end() - 5, inputname.end(), \"\") + \"_\" + asample + stune + \"_analyze9\";\n",
    "        outroot = outname + \".root\";\n",
    "\n",
    "        # set up the outputs\n",
    "        pdfname = outname;\n",
    "    } else {\n",
    "        std::string outname = inputname.replace(inputname.end() - 5, inputname.end(), \"\") + stune + \"_analyze9\";\n",
    "        outroot = outname + \".root\";\n",
    "\n",
    "        # set up the outputs\n",
    "        pdfname = outname;\n",
    "    }\n",
    "    TFile* o = TFile::Open(outroot.c_str(), \"RECREATE\");\n",
    "    targetobj.Write();\n",
    "    h_flux_dewidthed.Write();\n",
    "    std::string pdffilename1D = pdfname + \"_1D.pdf\";\n",
    "    std::string pdfstart1D = pdfname + \"_1D.pdf(\";\n",
    "    std::string pdfend1D = pdfname + \"_1D.pdf)\";\n",
    "\n",
    "    std::string pdffilename1Dres = pdfname + \"_1Dres.pdf\";\n",
    "    std::string pdfstart1Dres = pdfname + \"_1Dres.pdf(\";\n",
    "    std::string pdfend1Dres = pdfname + \"_1Dres.pdf)\";\n",
    "\n",
    "    std::string pdffilename2D = pdfname + \"_2D.pdf\";\n",
    "    std::string pdfstart2D = pdfname + \"_2D.pdf(\";\n",
    "    std::string pdfend2D = pdfname + \"_2D.pdf)\";\n",
    "\n",
    "    o.cd();\n",
    "    for (auto s : hists1D) {\n",
    "        auto sample = s.first;\n",
    "        for (auto v : hists1D[sample]) {\n",
    "            auto variable = v.first;\n",
    "            for (auto t : hists1D[sample][variable]) {\n",
    "                auto type = t.first;\n",
    "                for (auto c : hists1D[sample][variable][type]) {\n",
    "                    auto category = c.first;\n",
    "                    print(\" write out \" , hists1D[sample][variable][type][category].GetName() )\n",
    "                    hists1D[sample][variable][type][category].Write();\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    o.cd();\n",
    "    for (auto config : allconfigs) {\n",
    "        print(\" write out config \" , config.first )\n",
    "        std::string obj = config.second.ToString();\n",
    "        TNamed object(config.first, obj.c_str());\n",
    "        object.Write();\n",
    "    }\n",
    "    # Set up pdf for 1D plots.\n",
    "    TCanvas canvas1D(pdffilename1D.c_str());\n",
    "    canvas1D.SetLeftMargin(0.15);\n",
    "    canvas1D.SetRightMargin(0.15);\n",
    "    canvas1D.SetBottomMargin(0.15);\n",
    "    canvas1D.SetTopMargin(0.15);\n",
    "    canvas1D.Print(pdfstart1D.c_str(), \"pdf\");\n",
    "\n",
    "    # bool binwid = true;  # flag you need if MnvPlotter does not do binwid correction.  If it does not, you need to set this to true\n",
    "\n",
    "    print(\" just before 1D loop\" )\n",
    "    for (auto samples : hists1D) {\n",
    "        std::string sample = samples.first;\n",
    "        print(\" Sample: \" , sample )\n",
    "        for (auto variables : hists1D[sample]) {  # only do this for a subset to save output time.\n",
    "\n",
    "            std::string variable = variables.first;\n",
    "            if (!checktag(AnalyzeVariables, variable)) {\n",
    "                print(\" don't do this variable for now\" , variable )\n",
    "                continue;\n",
    "            }\n",
    "            print(\"  Variable: \" , variable )\n",
    "            std::string basename = \"h_\" + sample + \"_\" + variable;\n",
    "            if (singlesample) {\n",
    "                basename = \"h_\" + variable;\n",
    "            }\n",
    "            print(\"basename is \" , basename )\n",
    "            int exit = GetCrossSection(sample, variable, basename, hists1D[sample][variable], response1D[sample][variable], allconfigs, canvas1D, norm, POTScale, h_flux_dewidthed, unfold, num_iter, DEBUG, hasbkgsub, usetune, pdfname);\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def gethists(config):\n",
    "configname = \"./Try.json\"\n",
    "f = open(configname,'r')\n",
    "config = commentjson.load(f)\n",
    "dataHist = {}\n",
    "fitHists = {}\n",
    "unfitHists = {}\n",
    "\n",
    "\n",
    "\n",
    "    lowBin = 1\n",
    "    if \"LowBin\" in config: \n",
    "        lowBin = config[\"LowBin\"]\n",
    "    \n",
    "    upperLimit=2.0\n",
    "    if \"UpperLimit\" in config:\n",
    "        upperLimit =config[\"UpperLimit\"]\n",
    "    \n",
    "    inputFileName=config[\"InputFile\"]\n",
    "    outputFileName = config[\"OutputFile\"]\n",
    "    logPlot = config[\"LogPlot\"]\n",
    "    logMinimum = config[\"LogMinimum\"]\n",
    "    sidebands = config[\"Sidebands\"]\n",
    "    categories = config[\"Categories\"]\n",
    "    \n",
    "    # use this to exclude or include sidebands in the global fit\n",
    "    include = config[\"IncludeInFit\"]\n",
    "    backgrounds = config[\"Backgrounds\"]\n",
    "    \n",
    "\n",
    "    includeInFit={}\n",
    "    for s in sidebands:\n",
    "        includeInFit[s] = False\n",
    "        for  i in include:\n",
    "            if (s == i): includeInFit[s] = True\n",
    "        \n",
    "    \n",
    "    #varName = config[\"Variable\"]\n",
    "    fitType = config[\"FitType\"]\n",
    "    h_template = config[\"Template\"]\n",
    "    f_template = config[\"FitTemplate\"]\n",
    "\n",
    "    rebin=1\n",
    "    if \"Rebin\" in config:\n",
    "        rebin = config[\"Rebin\"]\n",
    "\n",
    "    inputFile = ROOT.TFile.Open(inputFileName,\"READ\")\n",
    "    outputfile = ROOT.TFile.Open(outputFileName,\"RECREATE\")\n",
    "    #loop on all entries of this directory\n",
    "    \n",
    "    outputfile.cd()\n",
    "    \n",
    "    pot_summary = inputFile.Get(\"POT_summary\")\n",
    "    potinfo = np.array([0.0,0.0])\n",
    "    potinfo[0]=pot_summary.GetBinContent(1)\n",
    "    potinfo[1]=pot_summary.GetBinContent(3) # this includes any prescale\n",
    "    pot_summary.Print(\"ALL\")\n",
    "    mcPOT = potinfo[1]\n",
    "    dataPOT = potinfo[0]\n",
    "    print (\"POT\", dataPOT,mcPOT)\n",
    "    POTscale = potinfo[0]/potinfo[1]\n",
    "  \n",
    "    print (\"POT scale factor: \" , POTscale)\n",
    "    \n",
    "    # make and fill maps that contain poers to the histograms you want to fit  uses CCQEMAT template\n",
    "    \n",
    "    #h_template = \"h___%s___%s___%s___reconstructed\";\n",
    "    # dataHist = {}\n",
    "    # fitHists = {}\n",
    "    # unfitHists = {}\n",
    "    \n",
    "    name = config[\"Variable\"]\n",
    "\n",
    "    for side in sidebands:\n",
    "        cat = \"data\"\n",
    "        cname = h_template%(side, cat,varName)\n",
    "        cname = h_template%(side, cat,varName)\n",
    "        fname = f_template%(side, cat,varName)\n",
    "        print ( \" look for \" , cname )\n",
    "        dataHist[side] = PlotUtils.MnvH1D()\n",
    "        dataHist[side] = inputFile.Get(cname)\n",
    "        \n",
    "        dataHist[side].Rebin(rebin)\n",
    "        dataHist[side].Write()\n",
    "        unfitHists[side] = []\n",
    "        fitHists[side] = []\n",
    "        print ( \" nbins \" , cname , \" \" , dataHist[side].GetXaxis().GetNbins() )\n",
    "        if (logPlot): dataHist[side].SetMinimum(logMinimum)\n",
    "        #dataHist[side].SetNormBinWidth(1.0);\n",
    "        #dataHist[sidename] = (TH1D*)dataHist.GetCVHistoWithStatError().Clone();\n",
    "        for  cat in categories:\n",
    "            cname = h_template%(side, cat,varName)\n",
    "            fname = f_template%(side, cat,varName)\n",
    "            name = cname\n",
    "            print ( \" look for \" , cname )\n",
    "            newhist = PlotUtils.MnvH1D()\n",
    "            newhist = inputFile.Get(cname)\n",
    "            if not newhist:\n",
    "                print ( \" no \" , cname )\n",
    "            \n",
    "            newhist.Rebin(rebin);\n",
    "            if (logPlot): newhist.SetMinimum(logMinimum)\n",
    "            print ( \"nbins \" , cname , \" \" , newhist.GetXaxis().GetNbins() )\n",
    "            \n",
    "            newhist.Scale(POTscale)\n",
    "            newhist.Print()\n",
    "            newhist.Write()\n",
    "            unfitHists[side].append(newhist)\n",
    "            fitHists[side].append(newhist.Clone(fname))\n",
    "            \n",
    "        \n",
    "        # /*for ( i = 0; i < categories.size(); i++){\n",
    "        #     unfitHists[side][i].SetNormBinWidth(1.0);\n",
    "        #     fitHists[side][i].SetNormBinWidth(1.0);\n",
    "        # }*/\n",
    "\n",
    "return unFithists,fitHists    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configname = \"./Try.json\"\n",
    "f = open(configname,'r')\n",
    "config = commentjson.load(f)\n",
    "gethists(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1.28121225775791303e+00,9.26752433073161686e-01,2.34814205775936458e+00,1.19256001977170878e+00,2.06809555409070267e+00])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testarray = [[4.37913794018177847e-05,-2.70534311853663019e-04,7.68293601191285961e-04,-1.01035963754613244e-06,-6.33620216728098760e-05],\n",
    "[-2.70534311853663019e-04,3.72604389054405870e-03,-1.18219944391336363e-02,-4.50352671609323995e-05,7.55635486379529001e-03],\n",
    "[7.68293601191285961e-04,-1.18219944391336363e-02,4.08349797094741951e-02,1.10370908939183272e-03,-7.19945013816742918e-02],\n",
    "[-1.01035963754613244e-06,-4.50352671609323995e-05,1.10370908939183272e-03,7.35760891367070124e-04,-2.95373032784254745e-02],\n",
    "[-6.33620216728098760e-05,7.55635486379529001e-03,-7.19945013816742918e-02,-2.95373032784254745e-02,1.25567293391937773e+00]]\n",
    "\n",
    "testarray = [[4.51788475382673715e-05,-2.85364565733574869e-04,8.06084163862019428e-04,1.97705040158106509e-06,-8.40679740034714436e-05],\n",
    "[-2.85364565733574869e-04,3.93866790473751654e-03,-1.25468028770457200e-02,-1.61393981126265563e-04,1.16813750019919144e-02],\n",
    "[8.06084163862019428e-04,-1.25468028770457200e-02,4.43479016837736995e-02,2.13451152907324221e-03,-1.14147245052297855e-01],\n",
    "[1.97705040158106509e-06,-1.61393981126265563e-04,2.13451152907324221e-03,1.29665819930366560e-03,-5.22224042559752202e-02],\n",
    "[-8.40679740034714436e-05,1.16813750019919144e-02,-1.14147245052297855e-01,-5.22224042559752202e-02,2.19307068295353469e+00]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (testarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testvalues = [1.27933918566519456e+00,9.71067727320098717e-01,2.22202915442571713e+00,1.13399764790330382e+00,3.68119190607679014e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(5)\n",
    "for i in range(0,5):\n",
    "    errors[i] = np.sqrt(testarray[i][i])\n",
    "\n",
    "pr (errors)\n",
    "\n",
    "array = np.array(testarray)\n",
    "pr (array)\n",
    "\n",
    "correlations = array.copy()\n",
    "for i in range(0,5):\n",
    "    for j in range(0,5):\n",
    "        correlations[i][j] = array[i][j]/errors[i]/errors[j]\n",
    "\n",
    "pr (correlations)\n",
    "\n",
    "\n",
    "\n",
    "parameters = np.array(testvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvalues,eigvectors = np.linalg.eig(array)\n",
    "pr (eigvalues)\n",
    "pr (eigvectors)\n",
    "pr (np.round(eigvectors*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = []\n",
    "pr (values)\n",
    " \n",
    "for x in range(0,len(values)):\n",
    "    #pr (\"vec\",eigvectors[x])\n",
    "    vec = eigvectors[x]\n",
    "    new = eigvectors[x]*np.sqrt(eigvalues[x])\n",
    "    variants.append(new)\n",
    "    pr (\"new\",new)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(testvalues)\n",
    "Print(testvalues + variants[0])\n",
    "Print(testvalues - variants[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
